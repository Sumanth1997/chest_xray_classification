{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import kagglehub\n",
        "\n",
        "# Download latest version\n",
        "path = kagglehub.dataset_download(\"nih-chest-xrays/data\")\n",
        "\n",
        "print(\"Path to dataset files:\", path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rUXnfwaGpYvE",
        "outputId": "26684ed2-d9cb-48cb-d46d-8371bea563ec"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading from https://www.kaggle.com/api/v1/datasets/download/nih-chest-xrays/data?dataset_version_number=3...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 42.0G/42.0G [32:42<00:00, 23.0MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting files...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Path to dataset files: /root/.cache/kagglehub/datasets/nih-chest-xrays/data/versions/3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms, models\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "from PIL import Image"
      ],
      "metadata": {
        "id": "DcayYm3Gnsat"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ChestXRayDataset(Dataset):\n",
        "    def __init__(self, dataframe, image_dir, transform=None, multi_label=True):\n",
        "        \"\"\"\n",
        "        Custom Dataset for Chest X-Ray images\n",
        "\n",
        "        Args:\n",
        "            dataframe (pd.DataFrame): DataFrame containing image metadata\n",
        "            image_dir (str): Directory containing X-ray images\n",
        "            transform (callable, optional): Optional transform to be applied on an image\n",
        "            multi_label (bool): Whether classification is multi-label\n",
        "        \"\"\"\n",
        "        self.image_dir = image_dir\n",
        "        self.transform = transform\n",
        "\n",
        "        # Preprocessing labels\n",
        "        self.multi_label = multi_label\n",
        "        self.labels = dataframe['Finding Labels'].str.split('|')\n",
        "\n",
        "        # Create unique label list\n",
        "        all_labels = [label for sublist in self.labels for label in sublist]\n",
        "        self.unique_labels = list(set(all_labels))\n",
        "\n",
        "        # MultiLabelBinarizer for encoding\n",
        "        self.mlb = MultiLabelBinarizer()\n",
        "        self.mlb.fit([self.unique_labels])\n",
        "\n",
        "        # Image filenames\n",
        "        self.image_files = dataframe['Image Index'].tolist()\n",
        "\n",
        "        # Encode labels\n",
        "        self.encoded_labels = self.mlb.transform(self.labels)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_files)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_name = os.path.join(self.image_dir, self.image_files[idx])\n",
        "        image = Image.open(img_name).convert('RGB')\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        label = self.encoded_labels[idx]\n",
        "        return image, torch.FloatTensor(label)\n",
        "\n",
        "    def get_num_classes(self):\n",
        "        return len(self.unique_labels)\n",
        "\n",
        "    def get_class_names(self):\n",
        "        return self.unique_labels"
      ],
      "metadata": {
        "id": "_F33fg4RXMvG"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_transforms():\n",
        "    \"\"\"Create data augmentation and normalization transforms\"\"\"\n",
        "    return transforms.Compose([\n",
        "        transforms.Resize((224, 224)),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.RandomRotation(10),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(\n",
        "            mean=[0.485, 0.456, 0.406],\n",
        "            std=[0.229, 0.224, 0.225]\n",
        "        )\n",
        "    ])"
      ],
      "metadata": {
        "id": "XRznP0y7jh4b"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_accuracy(outputs, targets, threshold=0.5):\n",
        "    \"\"\"\n",
        "    Calculate accuracy for multi-label classification\n",
        "\n",
        "    Args:\n",
        "        outputs (torch.Tensor): Model predictions (logits)\n",
        "        targets (torch.Tensor): True labels\n",
        "        threshold (float): Threshold for positive prediction\n",
        "\n",
        "    Returns:\n",
        "        float: Accuracy of predictions\n",
        "    \"\"\"\n",
        "    # Apply sigmoid to get probabilities\n",
        "    probs = torch.sigmoid(outputs)\n",
        "\n",
        "    # Convert to binary predictions based on threshold\n",
        "    preds = (probs >= threshold).float()\n",
        "\n",
        "    # Calculate per-sample accuracy (exact match)\n",
        "    exact_match = torch.all(preds == targets, dim=1).float()\n",
        "    accuracy = exact_match.mean().item()\n",
        "\n",
        "    return accuracy"
      ],
      "metadata": {
        "id": "73fk92sIjWwG"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(model, dataloaders, criterion, optimizer, num_epochs=5):\n",
        "    \"\"\"\n",
        "    Train the ResNet model\n",
        "\n",
        "    Args:\n",
        "        model (nn.Module): ResNet model\n",
        "        dataloaders (dict): Dictionary of train and validation dataloaders\n",
        "        criterion (nn.Module): Loss function\n",
        "        optimizer (torch.optim): Optimizer\n",
        "        num_epochs (int): Number of training epochs\n",
        "    \"\"\"\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model.to(device)\n",
        "\n",
        "    best_loss = float('inf')\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print(f'Epoch {epoch+1}/{num_epochs}')\n",
        "\n",
        "        for phase in ['train', 'val']:\n",
        "            if phase == 'train':\n",
        "                model.train()\n",
        "            else:\n",
        "                model.eval()\n",
        "\n",
        "            running_loss = 0.0\n",
        "            running_accuracy = 0.0\n",
        "\n",
        "            with torch.set_grad_enabled(phase == 'train'):\n",
        "                for inputs, labels in dataloaders[phase]:\n",
        "                    inputs = inputs.to(device)\n",
        "                    labels = labels.to(device)\n",
        "\n",
        "                    optimizer.zero_grad()\n",
        "\n",
        "                    outputs = model(inputs)\n",
        "                    loss = criterion(outputs, labels)\n",
        "\n",
        "                    if phase == 'train':\n",
        "                        loss.backward()\n",
        "                        optimizer.step()\n",
        "\n",
        "                    running_loss += loss.item() * inputs.size(0)\n",
        "\n",
        "                    # Calculate accuracy\n",
        "                    accuracy = calculate_accuracy(outputs, labels)\n",
        "                    running_accuracy += accuracy * inputs.size(0)\n",
        "\n",
        "            epoch_loss = running_loss / len(dataloaders[phase].dataset)\n",
        "            epoch_accuracy = running_accuracy / len(dataloaders[phase].dataset)\n",
        "\n",
        "            print(f'{phase} Loss: {epoch_loss:.4f}, {phase} Accuracy: {epoch_accuracy:.4f}')\n",
        "\n",
        "            if phase == 'val' and epoch_loss < best_loss:\n",
        "                best_loss = epoch_loss\n",
        "                torch.save(model.state_dict(), 'best_model.pth')"
      ],
      "metadata": {
        "id": "j8zTDAK9XSqz"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "    # Load metadata\n",
        "    df = pd.read_csv('3/Data_Entry_2017.csv')\n",
        "\n",
        "    # Split data\n",
        "    train_df, val_df = train_test_split(df, test_size=0.2, random_state=42)\n",
        "\n",
        "    # Create datasets and dataloaders\n",
        "    transform = create_transforms()\n",
        "\n",
        "    train_dataset = ChestXRayDataset(\n",
        "        train_df,\n",
        "        image_dir='allimages',\n",
        "        transform=transform\n",
        "    )\n",
        "\n",
        "    val_dataset = ChestXRayDataset(\n",
        "        val_df,\n",
        "        image_dir='allimages',\n",
        "        transform=transform\n",
        "    )\n",
        "\n",
        "    dataloaders = {\n",
        "        'train': DataLoader(train_dataset, batch_size=32, shuffle=True),\n",
        "        'val': DataLoader(val_dataset, batch_size=32)\n",
        "    }\n",
        "\n",
        "    # Initialize model\n",
        "    num_classes = train_dataset.get_num_classes()\n",
        "    class_names = train_dataset.get_class_names()\n",
        "    print(\"Number of classes:\", num_classes)\n",
        "    print(\"Class names:\", class_names)\n",
        "\n",
        "    model = models.resnet50(pretrained=True)\n",
        "    model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
        "\n",
        "    # Loss and optimizer\n",
        "    criterion = nn.BCEWithLogitsLoss()  # For multi-label classification\n",
        "    optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
        "\n",
        "    # Train\n",
        "    train_model(model, dataloaders, criterion, optimizer)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1YU9LbMQXbGo",
        "outputId": "3af49d2c-e2f4-467b-a20f-d680f69b2cc9"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of classes: 15\n",
            "Class names: ['Atelectasis', 'Effusion', 'Emphysema', 'Pneumothorax', 'Infiltration', 'Nodule', 'Edema', 'Pleural_Thickening', 'Pneumonia', 'Hernia', 'Cardiomegaly', 'Fibrosis', 'Consolidation', 'No Finding', 'Mass']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "train Loss: 0.1903, train Accuracy: 0.4127\n",
            "val Loss: 0.1820, val Accuracy: 0.4422\n",
            "Epoch 2/5\n",
            "train Loss: 0.1804, train Accuracy: 0.4236\n",
            "val Loss: 0.1787, val Accuracy: 0.4218\n",
            "Epoch 3/5\n",
            "train Loss: 0.1769, train Accuracy: 0.4310\n",
            "val Loss: 0.1769, val Accuracy: 0.4368\n",
            "Epoch 4/5\n",
            "train Loss: 0.1743, train Accuracy: 0.4366\n",
            "val Loss: 0.1746, val Accuracy: 0.4479\n",
            "Epoch 5/5\n",
            "train Loss: 0.1718, train Accuracy: 0.4414\n",
            "val Loss: 0.1743, val Accuracy: 0.4408\n"
          ]
        }
      ]
    }
  ]
}